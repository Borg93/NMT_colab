{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFYtpgsYt3Ko"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J2MbCH29fUv",
        "outputId": "50dab0e1-2ca9-4021-d502-d88dbf47dace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import and install"
      ],
      "metadata": {
        "id": "U58nxBSNZof5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlhUCS1fPesf"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q thai_segmenter\n",
        "!pip install -q transformers\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "FahIdyANa1O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from typing import List, Union\n",
        "import nltk\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "T8ZJPGKAYWuU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "WdNPTsnCZXld"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opus"
      ],
      "metadata": {
        "id": "NJlzIK1vZrc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Opus:\n",
        "    def __init__(self,model_name: str, device:str = None):\n",
        "        self._model_name = model_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self._model_name)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(self._model_name)\n",
        "\n",
        "        if device is None:\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.device = device\n",
        "\n",
        "        self.max_length = None\n",
        "    \n",
        "    def translate(self, documents: Union[str, List[str]], show_progress_bar: bool = False, beam_size: int = 5, \n",
        "                        batch_size: int = 16, paragraph_split: str = \"\\n\"):\n",
        "\n",
        "        if isinstance(documents, str):\n",
        "            translated_sent = self.model_translator(documents)\n",
        "            return translated_sent[0]\n",
        "        else:\n",
        "            # Split document into sentences\n",
        "            splitted_sentences = []\n",
        "            sent2doc = []\n",
        "            for doc in documents:\n",
        "                paragraphs = doc.split(paragraph_split) if paragraph_split is not None else [doc]\n",
        "                for para in paragraphs:\n",
        "                    for sent in self._sentence_splitting(para.strip()):\n",
        "                        sent = sent.strip()\n",
        "                        if len(sent) > 0:\n",
        "                            splitted_sentences.append(sent)\n",
        "                sent2doc.append(len(splitted_sentences))\n",
        "\n",
        "                translated_sentences = self.translate_sentences(splitted_sentences, show_progress_bar=show_progress_bar, beam_size=beam_size, batch_size=batch_size)\n",
        "\n",
        "            # Merge sentences back to documents\n",
        "            translated_docs = []\n",
        "            for doc_idx in range(len(documents)):\n",
        "                start_idx = sent2doc[doc_idx - 1] if doc_idx > 0 else 0\n",
        "                end_idx = sent2doc[doc_idx]\n",
        "                translated_docs.append(self._reconstruct_document(documents[doc_idx], splitted_sentences[start_idx:end_idx], translated_sentences[start_idx:end_idx]))\n",
        "\n",
        "            return translated_docs\n",
        "\n",
        "    def translate_sentences(self, sentences: Union[str, List[str]], show_progress_bar: bool = False, beam_size: int = 5, batch_size: int = 32):\n",
        "        #Sort by length to speed up processing\n",
        "        length_sorted_idx = np.argsort([-len(sen) for sen in sentences])\n",
        "        sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n",
        "\n",
        "        iterator = range(0, len(sentences_sorted), batch_size)\n",
        "        output = []\n",
        "\n",
        "        if show_progress_bar:\n",
        "            scale = min(batch_size, len(sentences))\n",
        "            iterator = tqdm.tqdm(iterator, total=len(sentences)/scale, unit_scale=scale, smoothing=0)\n",
        "\n",
        "        for start_idx in iterator:\n",
        "            output.extend(self.model_translator(sentences_sorted[start_idx:start_idx+batch_size], beam_size=beam_size))\n",
        "\n",
        "        #Restore original sorting of sentences\n",
        "        output = [output[idx] for idx in np.argsort(length_sorted_idx)]\n",
        "        \n",
        "        return output\n",
        "\n",
        "    def model_translator(self, sentences:str, beam_size:int=5):\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        inputs = self.tokenizer(sentences, truncation=True, padding=True, max_length=self.max_length, return_tensors=\"pt\").input_ids\n",
        "        inputs = inputs.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            translated = self.model.generate(inputs, num_beams=beam_size)\n",
        "            output = [self.tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def _sentence_splitting(text: str):\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt')\n",
        "        return nltk.sent_tokenize(text)\n",
        "\n",
        "    @staticmethod\n",
        "    def _reconstruct_document(doc, org_sent, translated_sent):\n",
        "          sent_idx = 0\n",
        "          char_idx = 0\n",
        "          translated_doc = \"\"\n",
        "          while char_idx < len(doc):\n",
        "              if sent_idx < len(org_sent) and doc[char_idx] == org_sent[sent_idx][0]:\n",
        "                  translated_doc += translated_sent[sent_idx]\n",
        "                  char_idx += len(org_sent[sent_idx])\n",
        "                  sent_idx += 1\n",
        "              else:\n",
        "                  translated_doc += doc[char_idx]\n",
        "                  char_idx += 1\n",
        "          return translated_doc"
      ],
      "metadata": {
        "id": "7r4Eu7MeZhl5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate"
      ],
      "metadata": {
        "id": "gbAbMNbuZudB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test translation"
      ],
      "metadata": {
        "id": "IrScCjF4i51Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Opus(\"Helsinki-NLP/opus-mt-en-sv\")"
      ],
      "metadata": {
        "id": "Y7eEE1pA2L30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"\"\"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\"\"]\n",
        "\n",
        "print(model.translate(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuMNoT1xSVIs",
        "outputId": "195bbf9a-a5d0-489d-a0c5-d24beaa19376"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tornet är 324 meter högt, ungefär lika högt som en byggnad med 81 våningar, och Paris högsta byggnad. Dess bas är kvadrat, mäter 125 meter (410 ft) på varje sida. Under sin konstruktion överträffade Eiffeltornet Washingtonmonumentet för att bli världens högsta konstgjordaste byggnad, en titel som det hade i 41 år tills Chryslerbyggnaden i New York blev färdig 1930. Det var den första byggnaden som nådde en höjd av 300 meter. På grund av att en sändningsantenn lades till på tornets ovansida 1957 är den nu högre än Chryslerbyggnaden med 5,2 meter (17 ft). Förutom sändare är Eiffeltornet den näst högsta fristående strukturen i Frankrike efter Millau Viaduct.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating hugginface_datasets"
      ],
      "metadata": {
        "id": "0SqNbzmEySio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMT:\n",
        "    def __init__(self, model:str, dataset_name, file_id, data_range_to_translate , data_type, skip_cols_to_translate, file_folder_drive ):\n",
        "        self.opus = model\n",
        "        self.dataset_name= dataset_name\n",
        "        self.file_id = file_id\n",
        "        self.data_range_to_translate = data_range_to_translate\n",
        "        self.data_type = data_type\n",
        "        self.skip_cols_to_translate = skip_cols_to_translate\n",
        "        self.file_folder_drive = file_folder_drive\n",
        "        self.dataset = load_dataset(self.dataset_name, split=f'{self.data_type}{self.data_range_to_translate}')\n",
        "        self.path = f'/content/drive/MyDrive/{self.file_folder_drive}/df_{self.dataset_name}_{self.data_type}{str(self.file_id)}.csv'\n",
        "\n",
        "        # print(self.dataset)\n",
        "\n",
        "    def translate_dataset(self, batch_size:int = 64, beam_size:int=5):\n",
        "        df_data_temp = []\n",
        "        col_list_dataset = list(self.dataset[0].keys())\n",
        "\n",
        "        for row_data in tqdm(self.dataset,desc='Translation in progress') :\n",
        "            row_data_temp = []\n",
        "            for c_list in col_list_dataset:\n",
        "                to_translate_row =row_data[c_list]\n",
        "                if c_list in skip_cols_to_translate:\n",
        "                    is_translated_row = to_translate_row\n",
        "                else:\n",
        "                    is_translated_row = self.opus.translate(to_translate_row, batch_size=batch_size,beam_size=beam_size)\n",
        "                row_data_temp.append(is_translated_row)\n",
        "            data_zip = tuple(row_data_temp)\n",
        "            df_data_temp.append(data_zip)\n",
        "\n",
        "        return pd.DataFrame(df_data_temp, columns = col_list_dataset)\n",
        "\n",
        "    def subdata_to_drive(self, df_trans):\n",
        "      with open(self.path, 'w', encoding = 'utf-8') as f:\n",
        "        df_trans.to_csv(f, sep=\";\")\n",
        "\n",
        "    @staticmethod\n",
        "    def assemble_df_data_type(file_folder_drive,dataset_name,data_type):\n",
        "      # setting the path for joining multiple files\n",
        "      files = os.path.join(f'/content/drive/MyDrive/{file_folder_drive}/', f'df_{dataset_name}_{data_type}*.csv')\n",
        "      files = glob.glob(files)\n",
        "      files.sort()\n",
        "      df_list = [pd.read_csv(f, sep=';') for f in files]  \n",
        "      df = pd.concat(df_list, ignore_index=True)    \n",
        "      df_merged = df.copy()\n",
        "      df_merged = df_merged.iloc[: , 1:]\n",
        "      return Dataset.from_pandas(df_merged)\n"
      ],
      "metadata": {
        "id": "eHvxEzKPpvgH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dict"
      ],
      "metadata": {
        "id": "JOzacnSh0TYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, tune this values after your hardware.\n",
        "Also, incremtnally change file_id and data_range_to_translate to assembly files afterwards (due to limitations of google colab idle).\n",
        "\n",
        "Local station you can just hammer on without be annoyed by splitting files and keeping track of ids.. + you can cache both model and dataset.."
      ],
      "metadata": {
        "id": "CXVLWLbw0ohK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"xsum\"\n",
        "file_id=1 \n",
        "data_type = \"train\"\n",
        "file_folder_drive = \"xsum\"\n",
        "data_range_to_translate= \"[0:5]\"\n",
        "skip_cols_to_translate=['id']\n",
        "\n",
        "nmt = NMT( model, dataset_name, file_id, data_range_to_translate , data_type, skip_cols_to_translate, file_folder_drive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKfavcwHykak",
        "outputId": "96fd2e69-31e1-4c4a-b0ae-f6b4aa5697c0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans= nmt.translate_dataset()\n",
        "nmt.subdata_to_drive(df_trans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "349a0bb2485146b8b5e4dad4f4c5cbde",
            "d835390385dd4ee5995c7e1e5a073c35",
            "f537185279514d6992a67e8d8f86de79",
            "4511db05dace46f5b65afdebf3b4440b",
            "d4c0e3ff14b040a08228f7e7fe7c599d",
            "ece8069228e8476b81575a527e12bf50",
            "b45ed936054247b5acfef30d48601f69",
            "95d7ef379ec046b9a902af67f7fd110b",
            "bdcabd31a9e54253ad8d650587aa1438",
            "3fb7ecb83c0343119e17ea8b84cf3891",
            "4a302cd7168d4adb9de27ad7ab286351"
          ]
        },
        "id": "cexDAQCA0mwN",
        "outputId": "d4834617-4d0b-44ad-db4b-76f4e88c666b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Translation in progress:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "349a0bb2485146b8b5e4dad4f4c5cbde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After translation of all files.. Assemble train, test, val"
      ],
      "metadata": {
        "id": "SOBpp67O06Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = nmt.assemble_df_data_type(\"xsum\", \"xsum\",\"train\")\n",
        "# test_dataset = nmt.assemble_df_data_type(\"xsum\", \"xsum\",\"test\")\n",
        "# val_dataset =  nmt.assemble_df_data_type(\"xsum\", \"xsum\",\"val\")"
      ],
      "metadata": {
        "id": "2KB0kvO5ud-x"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_dataset_dict = DatasetDict({\"train\":train_dataset,\"test\":test_dataset,\"validation\":val_dataset})"
      ],
      "metadata": {
        "id": "69d2lOAOaN9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "push to hub"
      ],
      "metadata": {
        "id": "18A2eyum0_3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "master_dataset_dict.push_to_hub(\"Gabriel/xsum_swe\")"
      ],
      "metadata": {
        "id": "T0p3XQFCaNyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptl337rZaNxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "U58nxBSNZof5",
        "NJlzIK1vZrc6",
        "0SqNbzmEySio"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "349a0bb2485146b8b5e4dad4f4c5cbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d835390385dd4ee5995c7e1e5a073c35",
              "IPY_MODEL_f537185279514d6992a67e8d8f86de79",
              "IPY_MODEL_4511db05dace46f5b65afdebf3b4440b"
            ],
            "layout": "IPY_MODEL_d4c0e3ff14b040a08228f7e7fe7c599d"
          }
        },
        "d835390385dd4ee5995c7e1e5a073c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece8069228e8476b81575a527e12bf50",
            "placeholder": "​",
            "style": "IPY_MODEL_b45ed936054247b5acfef30d48601f69",
            "value": "Translation in progress: 100%"
          }
        },
        "f537185279514d6992a67e8d8f86de79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d7ef379ec046b9a902af67f7fd110b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bdcabd31a9e54253ad8d650587aa1438",
            "value": 5
          }
        },
        "4511db05dace46f5b65afdebf3b4440b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb7ecb83c0343119e17ea8b84cf3891",
            "placeholder": "​",
            "style": "IPY_MODEL_4a302cd7168d4adb9de27ad7ab286351",
            "value": " 5/5 [00:16&lt;00:00,  3.53s/it]"
          }
        },
        "d4c0e3ff14b040a08228f7e7fe7c599d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece8069228e8476b81575a527e12bf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45ed936054247b5acfef30d48601f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d7ef379ec046b9a902af67f7fd110b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcabd31a9e54253ad8d650587aa1438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb7ecb83c0343119e17ea8b84cf3891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a302cd7168d4adb9de27ad7ab286351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}